{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Data Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facebook_scraper\n",
      "  Downloading facebook_scraper-0.2.59-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (1.26.1)\n",
      "Collecting dateparser<2.0.0,>=1.0.0 (from facebook_scraper)\n",
      "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting demjson3<4.0.0,>=3.0.5 (from facebook_scraper)\n",
      "  Downloading demjson3-3.0.6.tar.gz (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting requests-html<0.11.0,>=0.10.0 (from facebook_scraper)\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Collecting regex!=2019.02.19,!=2021.8.27 (from dateparser<2.0.0,>=1.0.0->facebook_scraper)\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m744.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzlocal (from dateparser<2.0.0,>=1.0.0->facebook_scraper)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.31.0)\n",
      "Collecting pyquery (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting fake-useragent (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading fake_useragent-1.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting parse (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading parse-1.19.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Collecting bs4 (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting w3lib (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyppeteer>=0.0.14 (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: certifi>=2021 in /home/codespace/.local/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2023.7.22)\n",
      "Collecting importlib-metadata>=1.4 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tqdm<5.0.0,>=4.42.1 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.10/site-packages (from bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.12.2)\n",
      "Collecting lxml>=2.1 (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting cssselect>=1.2.0 (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.4)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4->bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.5)\n",
      "Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fake_useragent-1.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Building wheels for collected packages: demjson3, bs4\n",
      "  Building wheel for demjson3 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for demjson3: filename=demjson3-3.0.6-py3-none-any.whl size=75281 sha256=dd1eab2a4542f7df07661e561cb68854452817998fe27f3eec3f88799d399040\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/2d/32/af/75c810e14c7ca0df40c20c662fcc7f33d1e055937b4e452cc1\n",
      "  Building wheel for bs4 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=83630ee4d5fd1d27514bde505fb38e5874a87e1ae04ca9c889b225318402e4fe\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
      "Successfully built demjson3 bs4\n",
      "Installing collected packages: pyee, parse, fake-useragent, demjson3, appdirs, zipp, websockets, w3lib, urllib3, tzlocal, tqdm, regex, lxml, cssselect, pyquery, importlib-metadata, dateparser, bs4, pyppeteer, requests-html, facebook_scraper\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.7\n",
      "    Uninstalling urllib3-2.0.7:\n",
      "      Successfully uninstalled urllib3-2.0.7\n",
      "Successfully installed appdirs-1.4.4 bs4-0.0.1 cssselect-1.2.0 dateparser-1.1.8 demjson3-3.0.6 facebook_scraper-0.2.59 fake-useragent-1.3.0 importlib-metadata-6.8.0 lxml-4.9.3 parse-1.19.1 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 regex-2023.10.3 requests-html-0.10.0 tqdm-4.66.1 tzlocal-5.2 urllib3-1.26.18 w3lib-2.1.2 websockets-10.4 zipp-3.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install facebook_scraper pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.8/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facebook_scraper import get_posts\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FANPAGE_LINK =\"hotwheels\"\n",
    "FOLDER_PATH = \"Data/\"\n",
    "COOKIE_PATH = \"./cookies.txt\"\n",
    "\n",
    "PAGES_NUMBER = 10 # Number of pages to crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list = []\n",
    "for post in get_posts(FANPAGE_LINK,\n",
    "                    options={\"comments\": True, \"reactions\": True, \"allow_extra_requests\": True},\n",
    "                    extra_info=True, pages=PAGES_NUMBER, cookies=COOKIE_PATH):\n",
    "    print(post)\n",
    "    post_list.append(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu file và chuyển dict thành df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/hotwheels.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataframe to scrape Facebook post\n",
    "post_df_full = pd.DataFrame(columns=post_list[0].keys(), index=range(len(post_list)), data=post_list)\n",
    "\n",
    "# To df\n",
    "path=FOLDER_PATH + FANPAGE_LINK + \".csv\"\n",
    "post_df_full.to_csv(path, index=False)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
